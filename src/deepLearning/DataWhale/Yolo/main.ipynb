{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Êñá‰ª∂‰∏ãËΩΩÊàêÂäü\n"
     ]
    }
   ],
   "source": [
    "\"\"\"_summary_\n",
    "\"\"\"\n",
    "import requests\n",
    "response = requests.get(\"http://mirror.coggle.club/seg_risky_training_anno.csv\")\n",
    "# Ê£ÄÊü•ËØ∑Ê±ÇÊòØÂê¶ÊàêÂäü\n",
    "if response.status_code == 200:\n",
    "    with open(\"/home/tipriest/data/seg_risky/seg_risky_training_anno.csv\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "        print(\"Êñá‰ª∂‰∏ãËΩΩÊàêÂäü\")\n",
    "else:\n",
    "    print(\"Êñá‰ª∂‰∏ãËΩΩÂ§±Ë¥•\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt update > /dev/null; apt install aria2 git-lfs axel -y > /dev/null\n",
    "# !pip install ultralytics==8.2.0 numpy pandas opencv-python Pillow matplotlib > /dev/null\n",
    "# !axel -n 12 -a  http://mirror.coggle.club/seg_risky_training_data_01.zip -o ~/data/seg_risky/seg_risky_training_data_01.zip\n",
    "# !unzip -q /home/tipriest/data/seg_risky/training_data_10.zip -d /home/tipriest/data/seg_risky/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import glob\n",
    "import json\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ËøôÊòØ‰∏Ä‰∏™Á§∫‰æãÊ®°Âùó„ÄÇ\n",
    "\n",
    "Ê≠§Ê®°ÂùóÂåÖÂê´‰∏éÁ§∫‰æãÂäüËÉΩÁõ∏ÂÖ≥ÁöÑ‰ª£Á†Å„ÄÇ\n",
    "\"\"\"\n",
    "BASE_DATA_PATH = \"/home/tipriest/data/seg_risky\"\n",
    "# ‰∏ÄÂÖ±Êúâ1020575ÁöÑÊï∞ÊçÆ\n",
    "training_anno = pd.read_csv(os.path.join(\n",
    "    BASE_DATA_PATH, \"seg_risky_training_anno.csv\"))\n",
    "train_jpgs = []\n",
    "for i in range(0, 2, 1):\n",
    "    train_jpgs += [x.replace('/home/tipriest/data/seg_risky/', '')\n",
    "                    for x in glob.glob(os.path.join(BASE_DATA_PATH, f'{i}/*.jpg'))]\n",
    "training_anno = training_anno[training_anno['Path'].isin(train_jpgs)]\n",
    "training_anno['Polygons'] = training_anno['Polygons'].apply(json.loads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix\n",
      "d    64212\n",
      "3    64160\n",
      "c    63942\n",
      "a    63892\n",
      "f    63881\n",
      "2    63877\n",
      "b    63870\n",
      "6    63808\n",
      "8    63789\n",
      "0    63785\n",
      "7    63725\n",
      "4    63685\n",
      "9    63628\n",
      "5    63507\n",
      "1    63453\n",
      "e    63361\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(os.path.join(\n",
    "#     BASE_DATA_PATH, \"seg_risky_training_anno.csv\"))\n",
    "# df[['Prefix', 'Suffix']] = df['Path'].str.split('/', expand=True)\n",
    "# prefix_counts= df['Prefix'].value_counts()\n",
    "# print(prefix_counts)\n",
    "# for i in range(16):\n",
    "#     folder_name = format(i, 'x')\n",
    "#     folder_path = f\"folder_{folder_name}\"\n",
    "#     train_jpgs = [x for x in glob.glob(os.path.join(BASE_DATA_PATH, f'{folder_name}/*.jpg'))]\n",
    "#     print(i, len(train_jpgs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format dateset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO_SEG_DATASET_BASE_PATH = os.path.join(BASE_DATA_PATH, \"datasetYOLO\")\n",
    "YOLO_SEG_DATASET_TRAIN_PATH = os.path.join(YOLO_SEG_DATASET_BASE_PATH, \"train/\")\n",
    "YOLO_SEG_DATASET_VALID_PATH = os.path.join(YOLO_SEG_DATASET_BASE_PATH, \"valid/\")\n",
    "\n",
    "if os.path.exists(YOLO_SEG_DATASET_BASE_PATH):\n",
    "    shutil.rmtree(YOLO_SEG_DATASET_BASE_PATH)\n",
    "os.makedirs(YOLO_SEG_DATASET_TRAIN_PATH)\n",
    "os.makedirs(YOLO_SEG_DATASET_VALID_PATH)\n",
    "\n",
    "def normalize_polygon(polygon, img_width, img_height):\n",
    "    normalized_polygon = [(min(x, img_width) / img_width, min(y, img_height) / img_height) for x, y in polygon]\n",
    "    return normalized_polygon\n",
    "\n",
    "for row in training_anno.iloc[500:5500].iterrows():\n",
    "    shutil.copy(os.path.join(BASE_DATA_PATH, row[1].Path), YOLO_SEG_DATASET_TRAIN_PATH)\n",
    "    img = cv2.imread(os.path.join(BASE_DATA_PATH, row[1].Path))\n",
    "    img_height, img_width = img.shape[:2]\n",
    "    txt_filename = os.path.join(YOLO_SEG_DATASET_TRAIN_PATH + row[1].Path.split('/')[-1][:-4] + '.txt')\n",
    "    with open(txt_filename, 'w') as up:\n",
    "        for polygon in row[1].Polygons:\n",
    "            normalized_polygon = normalize_polygon(polygon, img_width, img_height)\n",
    "            normalized_coords = ' '.join([f'{coord[0]:.3f} {coord[1]:.3f}' for coord in normalized_polygon])\n",
    "            up.write(f'0 {normalized_coords}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Âà∂‰ΩúÈ™åËØÅÈõÜIII\n",
    "for row in training_anno.iloc[:500].iterrows():\n",
    "    shutil.copy(os.path.join(\n",
    "        BASE_DATA_PATH, row[1].Path), YOLO_SEG_DATASET_VALID_PATH)\n",
    "\n",
    "    img = cv2.imread(os.path.join(BASE_DATA_PATH, row[1].Path))\n",
    "    img_height, img_width = img.shape[:2]\n",
    "    txt_filename = os.path.join(\n",
    "        YOLO_SEG_DATASET_VALID_PATH + row[1].Path.split('/')[-1][:-4] + '.txt')\n",
    "    with open(txt_filename, 'w') as up:\n",
    "        for polygon in row[1].Polygons:\n",
    "            normalized_polygon = normalize_polygon(\n",
    "                polygon, img_width, img_height)\n",
    "            normalized_coords = ' '.join(\n",
    "                [f'{coord[0]:.3f} {coord[1]:.3f}' for coord in normalized_polygon])\n",
    "            up.write(f'0 {normalized_coords}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO_SEG_DATASET_BASE_PATH = os.path.join(BASE_DATA_PATH, \"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(), \"data.yaml\"), 'w') as up:\n",
    "    data_root = os.path.abspath(YOLO_SEG_DATASET_BASE_PATH)\n",
    "    up.write(f'''\n",
    "path: {data_root}\n",
    "train: train\n",
    "val: valid\n",
    "\n",
    "names:\n",
    "    0: alter\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model & Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://mirror.coggle.club/yolo/Arial.ttf -O /home/tipriest/.cache/torch/hub/checkpoints/Arial.ttf\n",
    "# !wget http://mirror.coggle.club/yolo/yolov8n-v8.2.0.pt -O /home/tipriest/.cache/torch/hub/checkpoints/yolov8n.pt\n",
    "# !wget http://mirror.coggle.club/yolo/yolov8n-seg-v8.2.0.pt -O /home/tipriest/.cache/torch/hub/checkpoints/yolov8n-seg.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.11 üöÄ Python-3.10.14 torch-2.4.1 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/home/tipriest/.cache/torch/hub/checkpoints/yolo11x.pt, data=/home/tipriest/Documents/AlgorithmPractice/src/deepLearning/DataWhale/Yolo/data.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=256, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
      "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
      "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
      "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  9                  -1  1   1476864  ultralytics.nn.modules.block.SPPF            [768, 768, 5]                 \n",
      " 10                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2   1700352  ultralytics.nn.modules.block.C3k2            [1536, 384, 2, True]          \n",
      " 17                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   5317632  ultralytics.nn.modules.block.C3k2            [1152, 768, 2, True]          \n",
      " 20                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
      " 23        [16, 19, 22]  1   3146707  ultralytics.nn.modules.head.Detect           [1, [384, 768, 768]]          \n",
      "YOLO11x summary: 631 layers, 56,874,931 parameters, 56,874,915 gradients, 195.4 GFLOPs\n",
      "\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLO11n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/tipriest/data/seg_risky/dataset/train.cache... 53877 images, 0 backgrounds, 18 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 53877/53877 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/20bc184a4ce6fb2b7da8292ea83b2673.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.046]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/20bf87ceeb9141bb1d23725b683e4b98.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.06]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/22bb834ee6967259179b65d875ac4756.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0059999]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/242e19afc691c5d9f60532593f605b1b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.051]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/2484d02fcdda24fc246af4173cbc9318.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0220001]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/24ad85f03d6f0a32828166d0a92ed7f7.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/2638ef88af174ba06f5092da56e7931a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/264cdebdd5ed3bfe199ca81a2cd1870d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/27a8fe63618f66dd7a39112ddfe38a80.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/288845a52e6351ff2f9d87da09796a91.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0059999]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/298362989a757c31c5db2697f26849d7.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.008]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/2ae4f2a3c0d90f79c6c673c80da66b64.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0120001]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/2bbe441d59b5a3ff4e887a58321a46a7.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0220001]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/2bd6a6aa32e490c214830ae5a01976ce.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0120001]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/2d0ca0158c8f2c9cc2c11004fd60019f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/2dd6d6e419044d453b6aa4c6f09f2dda.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.016]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/2df1df642b6951b6926370f26b28a249.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.01]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/2e06e45c03dcf3b51a979d87f10f688b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.056]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/tipriest/data/seg_risky/dataset/valid.cache... 10000 images, 0 backgrounds, 1 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/valid/2bec6ff53af2afd38998a727a2afd3cb.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.1060001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train2/labels.jpg... \n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "model_base_path = \"/home/tipriest/.cache/torch/hub/checkpoints\"\n",
    "# yolov8n-seg„ÄÅyolov8s-seg„ÄÅyolov8m-seg„ÄÅyolov8l-segÂíåyolov8x-segÔºåÊ®°ÂûãÁöÑÂ§ßÂ∞è‰æùÊ¨°ÈÄíÂ¢û\n",
    "# model = YOLO(os.path.join(model_base_path, \"yolo11x.pt\"))\n",
    "model = YOLO(os.path.join(model_base_path, \"yolo11x.pt\"))\n",
    "results = model.train(data=os.path.join(os.getcwd(), \"data.yaml\"), epochs=30, imgsz=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tipriest/anaconda3/envs/AIdefense/lib/python3.10/site-packages/ultralytics/nn/tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.13 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.0 üöÄ Python-3.10.14 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4080 SUPER, 15959MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train10/weights/best.pt, data=/home/tipriest/data/seg_risky/dataset/data.yaml, epochs=80, time=None, patience=100, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train11, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train11\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tipriest/anaconda3/envs/AIdefense/lib/python3.10/site-packages/ultralytics/nn/tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tipriest/anaconda3/envs/AIdefense/lib/python3.10/site-packages/ultralytics/utils/checks.py:640: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "/home/tipriest/anaconda3/envs/AIdefense/lib/python3.10/site-packages/ultralytics/engine/trainer.py:261: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/tipriest/data/seg_risky/dataset/train... 53685 images, 0 backgrounds, 4 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 53685/53685 [00:21<00:00, 2474.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/419cbae2e6875baae0f6f9fa30d9b815.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.026]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/4aa9b2f69cc486f873d4da8a4c188a49.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.1090001]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/4b3645e99e5019a89d9364aa5598c821.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.4005 1.113 ]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/4e3eeae731cd81c75dc0f26d26baaafc.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.195]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/tipriest/data/seg_risky/dataset/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/tipriest/data/seg_risky/dataset/valid... 10000 images, 0 backgrounds, 2 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:04<00:00, 2489.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/valid/43d1d818747b26c8933fb776f9a22ad6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.034]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/valid/4dfae1c26157b6fffa20568f697cf0a0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.008]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/tipriest/data/seg_risky/dataset/valid.cache\n",
      "Plotting labels to runs/segment/train11/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train11\u001b[0m\n",
      "Starting training for 80 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/80      5.25G     0.7634     0.8506     0.5322     0.9489          0        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [07:05<00:00,  7.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:38<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.968      0.899      0.951      0.811      0.965      0.894      0.946      0.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/80      5.21G     0.8308     0.9068     0.6233     0.9729          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:55<00:00,  8.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:37<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.949      0.868      0.929       0.77      0.944      0.862      0.922      0.632\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/80      5.27G     0.9502      1.022     0.7878      1.019          4        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:51<00:00,  8.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:37<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.928      0.821      0.897      0.713      0.925      0.817      0.891      0.603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/80      5.23G      1.054      1.123     0.9514      1.067          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:49<00:00,  8.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:37<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.928      0.817      0.892      0.714      0.924      0.811      0.885      0.592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/80      5.23G       1.05      1.118     0.9339      1.064          3        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:48<00:00,  8.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:37<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.929       0.82      0.898      0.715      0.926      0.817      0.892      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/80      5.27G      1.035       1.11     0.9146      1.058          4        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:49<00:00,  8.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:37<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.929      0.829      0.902       0.73      0.928      0.822      0.896      0.605\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/80      5.25G      1.017      1.085     0.8878      1.051          2        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:48<00:00,  8.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:37<00:00,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.946      0.844      0.917      0.748      0.943       0.84      0.912      0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/80      5.24G      1.006      1.074     0.8699      1.046          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:48<00:00,  8.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:37<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.949       0.85      0.922      0.757      0.947      0.844      0.917      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/80      5.24G     0.9997      1.068     0.8582      1.042          0        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:39<00:00,  8.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:36<00:00,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.946      0.859      0.927      0.764      0.953      0.849      0.922      0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/80      5.23G     0.9916      1.061     0.8403      1.039          5        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:39<00:00,  8.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:36<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.952      0.861      0.928      0.768      0.951      0.855      0.922      0.633\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/80      5.23G     0.9861       1.06     0.8339      1.036          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:39<00:00,  8.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:36<00:00,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.953       0.87      0.932      0.775       0.95      0.867      0.928      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/80      5.18G      0.974      1.045     0.8198      1.031          4        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:42<00:00,  8.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:38<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392       0.95      0.875      0.934      0.779      0.949      0.868      0.929      0.642\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/80       5.2G     0.9721      1.048     0.8156       1.03          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:53<00:00,  8.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:37<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.957      0.876      0.937      0.784      0.953      0.873      0.932      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/80       5.2G     0.9631      1.038     0.8064      1.027          2        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:49<00:00,  8.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:37<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.964      0.873      0.938      0.786       0.96       0.87      0.933      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/80      5.23G     0.9599      1.036     0.8001      1.025          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:48<00:00,  8.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:37<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.957      0.883      0.939      0.789      0.954       0.88      0.935      0.648\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/80      5.23G     0.9523      1.031     0.7914      1.021          0        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:48<00:00,  8.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:37<00:00,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.959      0.883       0.94       0.79      0.957      0.878      0.935       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/80      5.23G     0.9482      1.016       0.78      1.021          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:48<00:00,  8.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:37<00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.959      0.884      0.941      0.792      0.957      0.878      0.936      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/80      5.21G     0.9459       1.02     0.7812      1.019          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:48<00:00,  8.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:37<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.957      0.888      0.942      0.794      0.953      0.884      0.937      0.652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/80      5.21G     0.9418      1.015     0.7753      1.019          0        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:48<00:00,  8.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:37<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.962      0.884      0.942      0.795      0.958       0.88      0.938      0.653\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/80      5.18G     0.9379      1.013     0.7649      1.017          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:51<00:00,  8.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:37<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392       0.96      0.886      0.943      0.797      0.957      0.883      0.938      0.653\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/80      5.22G     0.9327      1.014     0.7568      1.015          3        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:50<00:00,  8.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:36<00:00,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.959      0.888      0.944      0.798      0.957      0.883      0.939      0.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/80      5.19G     0.9308      1.004     0.7576      1.012          4        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3356/3356 [06:46<00:00,  8.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:36<00:00,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14392      0.958      0.889      0.944      0.799      0.957      0.884      0.939      0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/80      5.15G     0.9247     0.9997     0.7469      1.009         39        512:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2716/3356 [05:29<01:19,  8.10it/s]"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"./runs/segment/train10/weights/best.pt\")\n",
    "results = model.train(data=os.path.join(YOLO_SEG_DATASET_BASE_PATH, \"data.yaml\"), epochs=80, imgsz=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ËÆ≠ÁªÉÂêéÈúÄË¶ÅÂú®ËøôÈáåÂä†ËΩΩÊúÄÂ•ΩÁöÑÊ®°Âûã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "model = YOLO(\"./runs/segment/train10/weights/best.pt\")\n",
    "\n",
    "test_imgs = glob.glob(os.path.join(BASE_DATA_PATH, \"test_set_A_rename/*/*\"))\n",
    "# test_imgs = glob.glob(os.path.join(base_data_path, \"data_set/train/0/*\"))\n",
    "# print(os.path.join(base_data_path, \"data_set/train/0/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100000/100000 [11:06<00:00, 149.95it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "Polygon = []\n",
    "for path in tqdm(test_imgs[:]):\n",
    "    # print(path)\n",
    "    results = model(path, verbose=False)\n",
    "    result = results[0]\n",
    "    if result.masks is None:\n",
    "        Polygon.append([])\n",
    "    else:\n",
    "        image_polygons = []\n",
    "        for mask in result.masks.xy:\n",
    "            # Â∞ÜÊé©ËÜúÁöÑÂùêÊ†áËΩ¨Êç¢‰∏∫NumpyÊï∞ÁªÑ\n",
    "            mask_coords = np.array(mask)\n",
    "            # Ëé∑ÂèñÂ§ñÊé•Áü©ÂΩ¢(bounding box)\n",
    "            # print(mask_coords)\n",
    "            # print()\n",
    "            if 0 == mask_coords.size:\n",
    "                continue\n",
    "            x_min = round(float(np.min(mask_coords[:, 0])), 1)\n",
    "            x_max = round(float(np.max(mask_coords[:, 0])), 1)\n",
    "            y_min = round(float(np.min(mask_coords[:, 1])), 1)\n",
    "            y_max = round(float(np.max(mask_coords[:, 1])), 1)\n",
    "            bounding_box = [\n",
    "                [x_min, y_min],\n",
    "                [x_min, y_max],\n",
    "                [x_max, y_max],\n",
    "                [x_max, y_min]\n",
    "            ]\n",
    "            image_polygons.append(bounding_box)\n",
    "            # print(bounding_box)\n",
    "        Polygon.append(image_polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "submit = pd.DataFrame({\n",
    "    'Path': [x.split('/')[-1] for x in test_imgs[:]],\n",
    "    'Polygon': Polygon\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.merge(submit, pd.DataFrame({'Path': [x.split('/')[-1] for x in test_imgs[:]]}), on='Path', how='right')\n",
    "submit = submit.fillna('[]')\n",
    "submit.to_csv('track2_submit.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIdefense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
