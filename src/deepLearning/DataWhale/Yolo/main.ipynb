{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"_summary_\n",
    "\"\"\"\n",
    "import requests\n",
    "response = requests.get(\"http://mirror.coggle.club/seg_risky_training_anno.csv\")\n",
    "# 检查请求是否成功\n",
    "if response.status_code == 200:\n",
    "    with open(\"/home/tipriest/data/seg_risky/seg_risky_training_anno.csv\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "        print(\"文件下载成功\")\n",
    "else:\n",
    "    print(\"文件下载失败\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt update > /dev/null; apt install aria2 git-lfs axel -y > /dev/null\n",
    "# !pip install ultralytics==8.2.0 numpy pandas opencv-python Pillow matplotlib > /dev/null\n",
    "# !axel -n 12 -a  http://mirror.coggle.club/seg_risky_training_data_01.zip -o ~/data/seg_risky/seg_risky_training_data_01.zip\n",
    "# !unzip -q /home/tipriest/data/seg_risky/training_data_10.zip -d /home/tipriest/data/seg_risky/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import glob\n",
    "import json\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "这是一个示例模块。\n",
    "\n",
    "此模块包含与示例功能相关的代码。\n",
    "\"\"\"\n",
    "BASE_DATA_PATH = \"/home/tipriest/data/seg_risky\"\n",
    "# 一共有1020575的数据\n",
    "training_anno = pd.read_csv(os.path.join(\n",
    "    BASE_DATA_PATH, \"seg_risky_training_anno.csv\"))\n",
    "train_jpgs = []\n",
    "for i in range(0, 2, 1):\n",
    "    train_jpgs += [x.replace('/home/tipriest/data/seg_risky/', '')\n",
    "                    for x in glob.glob(os.path.join(BASE_DATA_PATH, f'{i}/*.jpg'))]\n",
    "training_anno = training_anno[training_anno['Path'].isin(train_jpgs)]\n",
    "training_anno['Polygons'] = training_anno['Polygons'].apply(json.loads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(\n",
    "#     BASE_DATA_PATH, \"seg_risky_training_anno.csv\"))\n",
    "# df[['Prefix', 'Suffix']] = df['Path'].str.split('/', expand=True)\n",
    "# prefix_counts= df['Prefix'].value_counts()\n",
    "# print(prefix_counts)\n",
    "# for i in range(16):\n",
    "#     folder_name = format(i, 'x')\n",
    "#     folder_path = f\"folder_{folder_name}\"\n",
    "#     train_jpgs = [x for x in glob.glob(os.path.join(BASE_DATA_PATH, f'{folder_name}/*.jpg'))]\n",
    "#     print(i, len(train_jpgs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format dateset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Format Train and Test Set\n",
    "\"\"\"\n",
    "YOLO_SEG_DATASET_BASE_PATH = os.path.join(BASE_DATA_PATH, \"datasetYOLO\")\n",
    "YOLO_SEG_DATASET_TRAIN_PATH = os.path.join(YOLO_SEG_DATASET_BASE_PATH, \"train/\")\n",
    "YOLO_SEG_DATASET_VALID_PATH = os.path.join(YOLO_SEG_DATASET_BASE_PATH, \"valid/\")\n",
    "\n",
    "if os.path.exists(YOLO_SEG_DATASET_BASE_PATH):\n",
    "    shutil.rmtree(YOLO_SEG_DATASET_BASE_PATH)\n",
    "os.makedirs(YOLO_SEG_DATASET_TRAIN_PATH)\n",
    "os.makedirs(YOLO_SEG_DATASET_VALID_PATH)\n",
    "\n",
    "def normalize_polygon(polygon, img_width, img_height):\n",
    "    normalized_polygon = [(min(x, img_width) / img_width, min(y, img_height) / img_height) for x, y in polygon]\n",
    "    return normalized_polygon\n",
    "\n",
    "for row in training_anno.iloc[20000:].iterrows():\n",
    "    shutil.copy(os.path.join(BASE_DATA_PATH, row[1].Path), YOLO_SEG_DATASET_TRAIN_PATH)\n",
    "    img = cv2.imread(os.path.join(BASE_DATA_PATH, row[1].Path))\n",
    "    img_height, img_width = img.shape[:2]\n",
    "    txt_filename = os.path.join(YOLO_SEG_DATASET_TRAIN_PATH + row[1].Path.split('/')[-1][:-4] + '.txt')\n",
    "    with open(txt_filename, 'w') as up:\n",
    "        for polygon in row[1].Polygons:\n",
    "            normalized_polygon = normalize_polygon(polygon, img_width, img_height)\n",
    "            normalized_coords = ' '.join([f'{coord[0]:.3f} {coord[1]:.3f}' for coord in normalized_polygon])\n",
    "            up.write(f'0 {normalized_coords}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制作验证集III\n",
    "for row in training_anno.iloc[:20000].iterrows():\n",
    "    shutil.copy(os.path.join(\n",
    "        BASE_DATA_PATH, row[1].Path), YOLO_SEG_DATASET_VALID_PATH)\n",
    "\n",
    "    img = cv2.imread(os.path.join(BASE_DATA_PATH, row[1].Path))\n",
    "    img_height, img_width = img.shape[:2]\n",
    "    txt_filename = os.path.join(\n",
    "        YOLO_SEG_DATASET_VALID_PATH + row[1].Path.split('/')[-1][:-4] + '.txt')\n",
    "    with open(txt_filename, 'w') as up:\n",
    "        for polygon in row[1].Polygons:\n",
    "            normalized_polygon = normalize_polygon(\n",
    "                polygon, img_width, img_height)\n",
    "            normalized_coords = ' '.join(\n",
    "                [f'{coord[0]:.3f} {coord[1]:.3f}' for coord in normalized_polygon])\n",
    "            up.write(f'0 {normalized_coords}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO_SEG_DATASET_BASE_PATH = os.path.join(BASE_DATA_PATH, \"datasetYOLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(), \"cfg/data.yaml\"), 'w') as up:\n",
    "    data_root = os.path.abspath(YOLO_SEG_DATASET_BASE_PATH)\n",
    "    up.write(f'''\n",
    "path: {data_root}\n",
    "train: train\n",
    "val: valid\n",
    "\n",
    "names:\n",
    "    0: alter\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model & Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://mirror.coggle.club/yolo/Arial.ttf -O /home/tipriest/.cache/torch/hub/checkpoints/Arial.ttf\n",
    "# !wget http://mirror.coggle.club/yolo/yolov8n-v8.2.0.pt -O /home/tipriest/.cache/torch/hub/checkpoints/yolov8n.pt\n",
    "# !wget http://mirror.coggle.club/yolo/yolov8n-seg-v8.2.0.pt -O /home/tipriest/.cache/torch/hub/checkpoints/yolov8n-seg.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from ultralytics import YOLO\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    model = YOLO(r'D:\\yolo\\yolov11\\ultralytics-main\\datasets\\yolo11.yaml')\n",
    "    model.train(data=r'D:\\yolo\\yolov11\\ultralytics-main\\datasets\\data.yaml',\n",
    "                cache=False,\n",
    "                imgsz=640,\n",
    "                epochs=100,\n",
    "                single_cls=False,  # 是否是单类别检测\n",
    "                batch=8,\n",
    "                close_mosaic=10,\n",
    "                workers=0,\n",
    "                device='0',\n",
    "                optimizer='SGD',\n",
    "                amp=True,\n",
    "                project='runs/train',\n",
    "                name='exp',\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "first train the model\n",
    "\"\"\"\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "model_base_path = \"/home/tipriest/.cache/torch/hub/checkpoints\"\n",
    "# yolov8n-seg、yolov8s-seg、yolov8m-seg、yolov8l-seg和yolov8x-seg，模型的大小依次递增\n",
    "# model = YOLO(os.path.join(model_base_path, \"yolo11x.pt\"))\n",
    "model = YOLO(os.path.join(model_base_path, \"yolo11x.pt\"))\n",
    "model.train(data=os.path.join(os.getcwd(), \"cfg/data.yaml\"), \n",
    "        cache=True,\n",
    "        imgsz=600,\n",
    "        epochs=100,\n",
    "        single_cls=True,  # 是否是单类别检测\n",
    "        batch=16,\n",
    "        close_mosaic=10,\n",
    "        workers=0,\n",
    "        device='0',\n",
    "        optimizer='SGD',\n",
    "        amp=True,\n",
    "        project='runs/train',\n",
    "        name='exp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"./runs/segment/exp3/weights/best.pt\")\n",
    "results = model.train(data=os.path.join(YOLO_SEG_DATASET_BASE_PATH, \"data.yaml\"), epochs=80, imgsz=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练后需要在这里加载最好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "训练之后加载模型\n",
    "\"\"\"\n",
    "import glob\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"./weights/best.pt\")\n",
    "BASE_DATA_PATH = \"/home/tipriest/data/seg_risky\"\n",
    "test_imgs = glob.glob(os.path.join(BASE_DATA_PATH, \"test_set_A_rename/*/*\"))\n",
    "# test_imgs = glob.glob(os.path.join(BASE_DATA_PATH, \"data_set/train/0/*\"))\n",
    "# print(os.path.join(BASE_DATA_PATH, \"data_set/train/0/*\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Instance Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "Polygon = []\n",
    "for path in tqdm(test_imgs[:]):\n",
    "    # print(path)\n",
    "    results = model(path, verbose=False)\n",
    "    result = results[0]\n",
    "    if result.masks is None:\n",
    "        Polygon.append([])\n",
    "    else:\n",
    "        image_polygons = []\n",
    "        for box in result.masks.xy:\n",
    "            # 将掩膜的坐标转换为Numpy数组\n",
    "            box_coords = np.array(box)\n",
    "            # 获取外接矩形(bounding box)\n",
    "            # print(mask_coords)\n",
    "            # print()\n",
    "            if 0 == box_coords.size:\n",
    "                continue\n",
    "            x_min = round(float(np.min(box_coords[:, 0])), 1)\n",
    "            x_max = round(float(np.max(box_coords[:, 0])), 1)\n",
    "            y_min = round(float(np.min(box_coords[:, 1])), 1)\n",
    "            y_max = round(float(np.max(box_coords[:, 1])), 1)\n",
    "            bounding_box = [\n",
    "                [x_min, y_min],\n",
    "                [x_min, y_max],\n",
    "                [x_max, y_max],\n",
    "                [x_max, y_min]\n",
    "            ]\n",
    "            image_polygons.append(bounding_box)\n",
    "            # print(bounding_box)\n",
    "        Polygon.append(image_polygons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "Polygon = []\n",
    "model.predict(source=test_imgs[1], save = True)\n",
    "for path in tqdm(test_imgs[:]):\n",
    "    # print(path)\n",
    "    results = model(path, verbose=False)\n",
    "    result = results[0]\n",
    "    if result.boxes is None:\n",
    "        Polygon.append([])\n",
    "    else:\n",
    "        image_polygons = []\n",
    "        for box in result.boxes.xyxy:\n",
    "            if 0 == box.size:\n",
    "                continue\n",
    "            # 将掩膜的坐标转换为Numpy数组\n",
    "            box_coords = np.array(box.cpu())\n",
    "            # 获取外接矩形(bounding box)\n",
    "            # print(mask_coords)\n",
    "            # print()\n",
    "            if 0 == box.size:\n",
    "                continue\n",
    "            x_min = round(float(np.min(box_coords[0])), 1)\n",
    "            x_max = round(float(np.max(box_coords[2])), 1)\n",
    "            y_min = round(float(np.min(box_coords[1])), 1)\n",
    "            y_max = round(float(np.max(box_coords[3])), 1)\n",
    "            bounding_box = [\n",
    "                [x_min, y_min],\n",
    "                [x_min, y_max],\n",
    "                [x_max, y_max],\n",
    "                [x_max, y_min]\n",
    "            ]\n",
    "            image_polygons.append(bounding_box)\n",
    "            # print(bounding_box)\n",
    "        Polygon.append(image_polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "submit = pd.DataFrame({\n",
    "    'Path': [x.split('/')[-1] for x in test_imgs[:]],\n",
    "    'Polygon': Polygon\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.merge(submit, pd.DataFrame({'Path': [x.split('/')[-1] for x in test_imgs[:]]}), on='Path', how='right')\n",
    "submit = submit.fillna('[]')\n",
    "submit.to_csv('track2_submit.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIdefense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
