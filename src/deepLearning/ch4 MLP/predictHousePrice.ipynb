{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "import requests\n",
    "DATA_HUB = dict()\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
    "\n",
    "def download(name, cache_dir = os.path.join('~', 'data')):\n",
    "    assert name in DATA_HUB, f\"{name}不存在于{DATA_HUB}\"\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    if os.path.exists(fname):\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname\n",
    "    print(f'正在从{url}中下载{fname}')\n",
    "    r = requests.get(url, stream=True, verify=True)\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return fname\n",
    "\n",
    "def download_extract(name, folder = None):\n",
    "    fname = download(name)\n",
    "    base_dir = os.path.dirname(fname)\n",
    "    data_dir, ext = os.path.splitext(fname)\n",
    "    if ext == '.zip':\n",
    "        fp = zipfile.ZipFile(fname, 'r')\n",
    "    elif ext in ('.tar', '.gz'):\n",
    "        fp = tarfile.open(fname, 'r')\n",
    "    else:\n",
    "        assert False, '只有zip/tar文件可以被解压缩'\n",
    "    fp.extractall(base_dir)\n",
    "    return os.path.join(base_dir, folder) if folder else data_dir\n",
    "\n",
    "def download_all():\n",
    "    for name in DATA_HUB:\n",
    "        download(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81) (1459, 80)\n",
      "(2919, 331)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "train_data = pd.read_csv('~/data/house-prices-advanced-regression-techniques/train.csv')\n",
    "test_data  = pd.read_csv('~/data/house-prices-advanced-regression-techniques/test.csv')\n",
    "print(train_data.shape, test_data.shape)\n",
    "# print(train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]])\n",
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:-1]))\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: (x-x.mean())/x.std()\n",
    ")\n",
    "# 在标准化数据之后，所有均值消失，因此可以将缺失值设置为0\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)\n",
    "# dummy_na = True将na视为有效地特征值，并为其创建指示符特征\n",
    "all_features = pd.get_dummies(all_features, dummy_na=True)\n",
    "print(all_features.shape)\n",
    "n_train = train_data.shape[0]\n",
    "train_features = torch.tensor(all_features[:n_train].values, dtype = torch.float32)\n",
    "test_features  = torch.tensor(all_features[n_train:].values, dtype = torch.float32)\n",
    "train_labels   = torch.tensor(\n",
    "    train_data.SalePrice.values.reshape(-1, 1), dtype=torch.float32\n",
    ")\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "in_features = train_features.shape[1]\n",
    "def get_net():\n",
    "    net = nn.Sequential(nn.Linear(in_features, 1))\n",
    "    return net\n",
    "\n",
    "def log_rsme(net, features, labels):\n",
    "    clipped_preds = torch.clamp(net(features), 1, float('inf'))\n",
    "    rmse = torch.sprt(loss(\n",
    "        torch.log(clipped_preds), torch.log(labels)\n",
    "    ))\n",
    "    return rmse.item()\n",
    "\n",
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "            num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_ls, test_ls = [], []\n",
    "    train_iter = d2l.load_array((train_features, train_labels), batch_size)\n",
    "    # Adam优化器\n",
    "    optimizer = torch.optim.Adam(\n",
    "        net.parameters(), lr = learning_rate, weight_decay=weight_decay)\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            l = loss(net(X), y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        train_ls.append(log_rsme(net, train_features, train_labels))\n",
    "        if test_labels is not None:\n",
    "            test_ls.append(log_rsme(net, test_features, test_labels))\n",
    "    return train_ls, test_ls\n",
    "\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k>1\n",
    "    fold_size = X.shape[0] // k\n",
    "    x_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j+1)*fold_size)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif x_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat([X.train, X_part], 0)\n",
    "            y_train = torch.cat([y.train, y_part], 0)\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "def k_fold(\n",
    "    k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_l_sum, valid_l_sum = 0, 0\n",
    "    \n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k, i, X_train, y_train)\n",
    "        net = get_net()\n",
    "        train_ls, valid_ls = train(\n",
    "            net, *data, num_epochs, learning_rate, weight_decay, batch_size\n",
    "        )\n",
    "        train_l_sum += train_ls[-1]\n",
    "        valid_l_sum += valid_ls[-1]\n",
    "        if i == 0:\n",
    "            d2l.plot(\n",
    "                list(range(1, num_epochs+1)), [train_ls, valid_ls], \n",
    "                xlabel='epoch', ylabel='rsme', xlim = [1, num_epochs],\n",
    "                legend=['train', 'valid'], yscale='log'\n",
    "            )\n",
    "        print(f'折{i+1}, 训练log rsme:{float(train_ls[-1]):f}', \n",
    "                f'验证log rsme{float(valid_ls[-1]):f}')\n",
    "    return train_l_sum / k, valid_l_sum / k\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'sprt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m k, num_epochs, lr, weight_decay, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m----> 2\u001b[0m train_l, valid_l \u001b[38;5;241m=\u001b[39m \u001b[43mk_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-折验证, 平均训练log rsme:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mfloat\u001b[39m(train_l)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124mf\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m验证log rsme\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mfloat\u001b[39m(valid_l)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124mf\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 81\u001b[0m, in \u001b[0;36mk_fold\u001b[0;34m(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size)\u001b[0m\n\u001b[1;32m     79\u001b[0m data \u001b[38;5;241m=\u001b[39m get_k_fold_data(k, i, X_train, y_train)\n\u001b[1;32m     80\u001b[0m net \u001b[38;5;241m=\u001b[39m get_net()\n\u001b[0;32m---> 81\u001b[0m train_ls, valid_ls \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m train_l_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_ls[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     85\u001b[0m valid_l_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m valid_ls[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[6], line 53\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, train_features, train_labels, test_features, test_labels, num_epochs, learning_rate, weight_decay, batch_size)\u001b[0m\n\u001b[1;32m     51\u001b[0m     l\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     52\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 53\u001b[0m train_ls\u001b[38;5;241m.\u001b[39mappend(\u001b[43mlog_rsme\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     test_ls\u001b[38;5;241m.\u001b[39mappend(log_rsme(net, test_features, test_labels))\n",
      "Cell \u001b[0;32mIn[6], line 35\u001b[0m, in \u001b[0;36mlog_rsme\u001b[0;34m(net, features, labels)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_rsme\u001b[39m(net, features, labels):\n\u001b[1;32m     34\u001b[0m     clipped_preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(net(features), \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 35\u001b[0m     rmse \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msprt\u001b[49m(loss(\n\u001b[1;32m     36\u001b[0m         torch\u001b[38;5;241m.\u001b[39mlog(clipped_preds), torch\u001b[38;5;241m.\u001b[39mlog(labels)\n\u001b[1;32m     37\u001b[0m     ))\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rmse\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/algorithmPractice/lib/python3.8/site-packages/torch/__init__.py:2216\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   2213\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m-> 2216\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'sprt'"
     ]
    }
   ],
   "source": [
    "\n",
    "k, num_epochs, lr, weight_decay, batch_size = 5, 100, 5, 0, 64\n",
    "train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr, weight_decay, batch_size)\n",
    "print(f'{k}-折验证, 平均训练log rsme:{float(train_l):f}', f'验证log rsme{float(valid_l):f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algorithmPractice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
